{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1fa700c9",
      "metadata": {
        "id": "1fa700c9"
      },
      "source": [
        "# Telco Customer Churn â€” **02_Modeling_Interpretation**\n",
        "*Prepared 2025-11-04 09:25 (WIB)*  \n",
        "*Author: Hans Christian*\n",
        "\n",
        "**Goal:** Build robust churn models with clear business interpretation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2eb045",
      "metadata": {
        "id": "ce2eb045"
      },
      "source": [
        "## Block 0 â€” Setup & Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install imbalanced-learn xgboost shap"
      ],
      "metadata": {
        "id": "-kznTlsFwpuD"
      },
      "id": "-kznTlsFwpuD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138bea3e",
      "metadata": {
        "id": "138bea3e"
      },
      "outputs": [],
      "source": [
        "# --- Imports dulu (sebelum pakai os) ---\n",
        "import os, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Colab mount & base path ---\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    drive.mount('/content/drive')\n",
        "    BASE = '/content/drive/MyDrive/Portofolio/1_Telco Customer Churn'\n",
        "else:\n",
        "    BASE = '/content/drive/MyDrive/Portofolio/1_Telco Customer Churn'  # sesuaikan jika lokal\n",
        "\n",
        "CLEAN_FILE = f\"{BASE}/data_clean/churn_clean.csv\"\n",
        "MODEL_DIR  = f\"{BASE}/models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# --- Load data bersih ---\n",
        "df = pd.read_csv(CLEAN_FILE)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02a2878",
      "metadata": {
        "id": "c02a2878"
      },
      "source": [
        "## Block 1 â€” Feature Split & Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7548eb9",
      "metadata": {
        "id": "c7548eb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "y = df[\"Churn\"].map({\"Yes\":1, \"No\":0}).astype(int)\n",
        "X = df.drop(columns=[\"Churn\", \"customerID\"], errors=\"ignore\")\n",
        "\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), num_cols),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1114e3b",
      "metadata": {
        "id": "a1114e3b"
      },
      "source": [
        "## Block 2 â€” Baseline: Logistic Regression (with SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8132187",
      "metadata": {
        "id": "f8132187"
      },
      "outputs": [],
      "source": [
        "\n",
        "pipe = ImbPipeline(steps=[\n",
        "    (\"pre\", pre),\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"clf\", LogisticRegression(max_iter=200, n_jobs=None))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "preds = pipe.predict(X_test)\n",
        "proba = pipe.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, proba))\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, proba)\n",
        "plt.title(\"ROC Curve â€” Logistic Regression (SMOTE)\")\n",
        "plt.show()\n",
        "\n",
        "joblib.dump(pipe, f\"{MODEL_DIR}/logreg_smote.joblib\")\n",
        "print(\"Saved model:\", f\"{MODEL_DIR}/logreg_smote.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2779dd4",
      "metadata": {
        "id": "f2779dd4"
      },
      "source": [
        "## Block 3 â€” Gradient Boosting (XGBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069061ea",
      "metadata": {
        "id": "069061ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = ImbPipeline(steps=[\n",
        "    (\"pre\", pre),\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"clf\", XGBClassifier(\n",
        "        n_estimators=400, max_depth=4, learning_rate=0.08, subsample=0.9, colsample_bytree=0.9,\n",
        "        reg_lambda=1.0, random_state=42, eval_metric=\"logloss\", n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "preds = xgb.predict(X_test)\n",
        "proba = xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, proba))\n",
        "RocCurveDisplay.from_predictions(y_test, proba)\n",
        "plt.title(\"ROC Curve â€” XGBoost (SMOTE)\")\n",
        "plt.show()\n",
        "\n",
        "joblib.dump(xgb, f\"{MODEL_DIR}/xgb_smote.joblib\")\n",
        "print(\"Saved model:\", f\"{MODEL_DIR}/xgb_smote.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd42caef",
      "metadata": {
        "id": "bd42caef"
      },
      "source": [
        "## Block 4 â€” Explainability SHAP KernelExplainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f8def3",
      "metadata": {
        "id": "52f8def3"
      },
      "outputs": [],
      "source": [
        "# --- Block 4 â€” Explainability (SHAP KernelExplainer, stable) ---\n",
        "\n",
        "# 0) Install (sekali saja di atas notebook kalau belum)\n",
        "# !pip -q install shap\n",
        "\n",
        "import shap, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Fungsi prediksi proba dari PIPELINE pada RAW FEATURES\n",
        "#    (KernelExplainer akan memanggil fungsi ini berulang)\n",
        "def predict_proba_raw(Xraw: np.ndarray):\n",
        "    Xdf = pd.DataFrame(Xraw, columns=X_train.columns)  # pastikan kolom sama urutan\n",
        "    return xgb.predict_proba(Xdf)[:, 1]                # pipeline xgb -> proba kelas \"churn=1\"\n",
        "\n",
        "# 2) Pilih background sample kecil agar cepat (representatif)\n",
        "rng = np.random.default_rng(42)\n",
        "bg_n   = min(200, len(X_train))\n",
        "test_n = min(100, len(X_test))\n",
        "\n",
        "bg_idx    = rng.choice(X_train.index, size=bg_n, replace=False)\n",
        "test_idx  = rng.choice(X_test.index,  size=test_n, replace=False)\n",
        "\n",
        "X_bg    = X_train.loc[bg_idx].copy()\n",
        "X_testS = X_test.loc[test_idx].copy()\n",
        "\n",
        "# 3) Buat KernelExplainer (gunakan link='logit' biar selaras dengan proba)\n",
        "explainer = shap.KernelExplainer(predict_proba_raw, X_bg, link=\"logit\")\n",
        "\n",
        "# 4) Hitung SHAP values untuk subset test\n",
        "#    nsamples: makin besar makin akurat namun lebih lambat (100â€“300 biasanya cukup)\n",
        "shap_values = explainer.shap_values(X_testS, nsamples=200)\n",
        "\n",
        "# 5) Summary plot (bar & beeswarm) â€” GLOBAL importance\n",
        "shap.summary_plot(shap_values, X_testS, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_values, X_testS, show=True)\n",
        "\n",
        "# 6) Waterfall untuk SATU pelanggan (LOCAL explanation)\n",
        "i = 0  # ganti index lokal yang ingin kamu jelaskan\n",
        "shap.waterfall_plot(shap.Explanation(\n",
        "    values=shap_values[i],\n",
        "    base_values=explainer.expected_value,\n",
        "    data=X_testS.iloc[i],\n",
        "    feature_names=X_testS.columns\n",
        "), max_display=20)\n",
        "plt.show()\n",
        "\n",
        "print(\"Done. Kernel SHAP berjalan (subset). Kamu bisa ubah bg_n/test_n/nsamples untuk akurasi vs kecepatan.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff2eb70",
      "metadata": {
        "id": "eff2eb70"
      },
      "source": [
        "## ðŸ§­ Block 5 â€” Business Interpretation & What-If"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea026bfa",
      "metadata": {
        "id": "ea026bfa"
      },
      "source": [
        "- Tulis insight utama: siapa yang berisiko churn? (contract=month-to-month, tenure rendah, charges tinggi, dsb.)\n",
        "- Rekomendasi: diskon/retention offer untuk segmen risiko tinggi; auto-flag ke CRM; A/B test untuk konfirmasi dampak.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install streamlit shap"
      ],
      "metadata": {
        "id": "to-pPWkk2tOJ"
      },
      "id": "to-pPWkk2tOJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Portofolio/1_Telco Customer Churn/dashboard\"\n",
        "!streamlit run churn_dashboard_app.py --server.port 8501 --server.address 0.0.0.0"
      ],
      "metadata": {
        "id": "mFQQyDB325iR"
      },
      "id": "mFQQyDB325iR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan Streamlit dengan auto-deteksi External URL\n",
        "!nohup streamlit run churn_dashboard_app.py --server.port 8501 --server.address 0.0.0.0 & sleep 5 && grep -o 'https://[0-9a-zA-Z.-]*\\.gradio\\.live' nohup.out"
      ],
      "metadata": {
        "id": "EEsfdmhl9SkQ"
      },
      "id": "EEsfdmhl9SkQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -o 'https://[0-9a-zA-Z.-]*\\.gradio\\.live' nohup.out"
      ],
      "metadata": {
        "id": "OO7Elu5Z_yjY"
      },
      "id": "OO7Elu5Z_yjY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}